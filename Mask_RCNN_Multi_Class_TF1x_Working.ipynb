{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun1724/NUCLS-Image-Segmentation/blob/main/Mask_RCNN_Multi_Class_TF1x_Working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3stgHmeSXjL"
      },
      "source": [
        "!pip install tensorflow==1.14\n",
        "!pip install tensorflow-gpu==1.14\n",
        "# # %tensorflow_version 1.x\n",
        "!pip install keras==2.1\n",
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX9jMZSVu7PA"
      },
      "source": [
        "**Manually restart runtime and then continue below**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDZ-DNl4T1Wj"
      },
      "source": [
        "# !pip install -q git+https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU1LTWa7SDzT"
      },
      "source": [
        "# !git clone -q https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6MGJ855StAe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENRnwyhpumwE"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/maskrcnn/Mask_RCNN /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRATZIpyTE3f"
      },
      "source": [
        "!cd ~Mask_RCNN\n",
        "!pip install -r /content/Mask_RCNN/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg27Hk2hUFXi"
      },
      "source": [
        "# !cp /content/drive/MyDrive/maskrcnn/mask_rcnn_coco.h5 /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDTTjQFFTsVR"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import xml.etree\n",
        "from numpy import zeros, asarray\n",
        "\n",
        "import Mask_RCNN.mrcnn.utils\n",
        "import Mask_RCNN.mrcnn.config\n",
        "import Mask_RCNN.mrcnn.model\n",
        "\n",
        "\n",
        "class NuCLSDataset(Mask_RCNN.mrcnn.utils.Dataset):\n",
        "\n",
        "\tdef load_dataset(self, dataset_dir, fold_num, is_train=True):\n",
        "\t\tself.add_class(\"dataset\", 1, \"Tumor\")\n",
        "\t\tself.add_class(\"dataset\", 2, \"Mitotic_f\")\n",
        "\t\tself.add_class(\"dataset\", 3, \"Stromal\")\n",
        "\t\tself.add_class(\"dataset\", 4, \"Macroph\")\n",
        "\t\tself.add_class(\"dataset\", 5, \"Lymphoc\")\n",
        "\t\tself.add_class(\"dataset\", 6, \"Plasma C\")\n",
        "\t\tself.add_class(\"dataset\", 7, \"Other\")\n",
        "\n",
        "\t\timages_dir = dataset_dir + '/train_test_splits'\n",
        "\t\tannotations_dir = dataset_dir + '/csv/'\n",
        "\n",
        "\t\tif is_train:\n",
        "\t\t  fold_file = images_dir + '/fold_' + str(fold_num) + '_train.csv'\n",
        "\t\telse:\n",
        "\t\t  fold_file = images_dir + '/fold_' + str(fold_num) + '_test.csv'\n",
        "\n",
        "\t\tdf = pd.DataFrame()\n",
        "\t\tdf = pd.read_csv(fold_file)\n",
        "\n",
        "\t\timage_file_path = dataset_dir + '/rgb/'\n",
        "\n",
        "\t\tfor i in range(len(df)):\n",
        "      \n",
        "\t\t\timages_paths = glob.glob(image_file_path + str(df.loc[i,'slide_name']) + '*')\n",
        "\n",
        "\t\t\tfor img_path in images_paths:\n",
        "\n",
        "\t\t\t\timage_id = img_path[len(img_path):][:-4] #filename[:-4]\n",
        "\n",
        "\t\t\t\tmask_path = img_path.replace('/QC/rgb/','/QC/mask/')\n",
        "\t\t\t\tann_path = img_path.replace('/QC/rgb/','/QC/csv/')\n",
        "\t\t\t\tann_path = ann_path.replace('.png','.csv')\n",
        "\t\t\t\tim = cv2.imread(img_path)\n",
        "\t\t\t\th, w, c = im.shape\n",
        "\t\t\t\tdf1 = pd.DataFrame()\n",
        "\t\t\t\tdf1 = pd.read_csv(ann_path)\n",
        "\t\t\t\timg_write = False\n",
        "\t\t\t\tfor i in range(len(df1)):\n",
        "\t\t\t\t\tclass_name = df1.loc[i,'group']\n",
        "\t\t\t\t\tif not class_name in ['apoptotic_body', 'correction_apoptotic_body', \n",
        "                           'unlabeled', 'correction_unlabeled']:\n",
        "\t\t\t\t\t\timg_write = True\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\t# if not class_name in class_names_list:\n",
        "\t\t\t\t\t\t# \tclass_names_list += [class_name]\n",
        "\t\t\t\t\t\t# \tprint(class_names_list)\n",
        "\t\t\t  # ann_path = annotations_dir + image_id + '.xml'\n",
        "\n",
        "\t\t\t\tif img_write:\n",
        "\t\t\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, h=h, w=w)\n",
        "\n",
        "\tdef extract_boxes(self, filename, width, height):\n",
        "   \n",
        "\t\tclass_list1 = ['tumor', 'correction_tumor']\n",
        "\t\tclass_list2 = ['mitotic_figure', 'correction_mitotic_figure']\n",
        "\t\tclass_list3 = ['fibroblast', 'correction_fibroblast',\n",
        "\t\t\t\t\t\t\t\t\t\t'vascular_endothelium', 'correction_vascular_endothelium']\n",
        "\t\tclass_list4 = ['macrophage', 'correction_macrophage']\n",
        "\t\tclass_list5 = ['lymphocyte', 'correction_lymphocyte']\n",
        "\t\tclass_list6 = ['plasma_cell', 'correction_plasma_cell']\n",
        "\t\tclass_list7 = ['neutrophil', 'correction_neutrophil',\n",
        "\t\t\t\t\t\t\t\t\t\t'eosinophil', 'correction_eosinophil',\n",
        "\t\t\t\t\t\t\t\t\t\t'myoepithelium', 'correction_myoepithelium',\n",
        "\t\t\t\t\t\t\t\t\t\t'ductal_epithelium', 'correction_ductal_epithelium']\n",
        "\n",
        "\t\tdf = pd.DataFrame()\n",
        "\t\tdf = pd.read_csv(filename)\n",
        "\n",
        "\t\tboxes = list()\n",
        "\t\tclass_ids = list()\n",
        "\n",
        "\t\tfor i in range(len(df)):\n",
        "\t\t\tclass_name = df.loc[i,'group']\n",
        "\t\t\tif not class_name in ['apoptotic_body', 'correction_apoptotic_body', \n",
        "                           'unlabeled', 'correction_unlabeled']:\n",
        "\t\t\t\txmin = int(df.loc[i,'xmin'])\n",
        "\t\t\t\tymin = int(df.loc[i,'ymin'])\n",
        "\t\t\t\txmax = int(df.loc[i,'xmax'])\n",
        "\t\t\t\tymax = int(df.loc[i,'ymax'])\n",
        "\t\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\t\t# print(class_name)\n",
        "\t\t\t\tif class_name in class_list1:\n",
        "\t\t\t\t\tid = 1\n",
        "\t\t\t\tif class_name in class_list2:\n",
        "\t\t\t\t\tid = 2\n",
        "\t\t\t\tif class_name in class_list3:\n",
        "\t\t\t\t\tid = 3\n",
        "\t\t\t\tif class_name in class_list4:\n",
        "\t\t\t\t\tid = 4\n",
        "\t\t\t\tif class_name in class_list5:\n",
        "\t\t\t\t\tid = 5\n",
        "\t\t\t\tif class_name in class_list6:\n",
        "\t\t\t\t\tid = 6\n",
        "\t\t\t\tif class_name in class_list7:\n",
        "\t\t\t\t\tid = 7\n",
        "\t\t\t\tboxes.append(coors)\n",
        "\t\t\t\tclass_ids.append(id)\n",
        "\n",
        "\t\t# print(boxes, width, height)\n",
        "\t\t# print(class_ids)\n",
        "\t\treturn boxes, width, height, class_ids\n",
        "\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\tpath = info['annotation']\n",
        "\t\twidth = info['w']\n",
        "\t\theight = info['h']\n",
        "\t\tboxes, w, h, class_ids = self.extract_boxes(path, width, height)\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# print(class_ids)\n",
        "\n",
        "\t\t# class_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\t# class_ids.append(self.class_names.index('tumor'))\n",
        "\t\t# print(masks, asarray(class_ids, dtype='int32'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm1q4QgwQY51"
      },
      "source": [
        "class TrainConfig(Mask_RCNN.mrcnn.config.Config):\n",
        "    NAME = \"Train_cfg\"\n",
        "\n",
        "    #IMAGE_MAX_DIM = 768\n",
        "    #IMAGE_MIN_DIM = 256\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    NUM_CLASSES = 7+1\n",
        "\n",
        "    STEPS_PER_EPOCH = 1000 // IMAGES_PER_GPU\n",
        "\n",
        "    VALIDATION_STEPS = 200 // IMAGES_PER_GPU\n",
        "\n",
        "Train_config = TrainConfig()\n",
        "Train_config.display()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFBxOvwKQGY1"
      },
      "source": [
        "# from matplotlib import pyplot\n",
        "\n",
        "# for i in range(100000):\n",
        "#   image_id = i\n",
        "#   image = valid_dataset.load_image(image_id)\n",
        "#   print(i, image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX_LfLL0yAjm"
      },
      "source": [
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.1), # horizontal flips\n",
        "    iaa.Flipud(0.1), # vertical flips\n",
        "    # iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "    # But we only blur about 50% of all images.\n",
        "    # iaa.Sometimes(\n",
        "    #     0.23,\n",
        "    #     iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    # ),\n",
        "    # Strengthen or weaken the contrast in each image.\n",
        "    # iaa.Sometimes(\n",
        "    #     0.23,\n",
        "    #     iaa.LinearContrast((0.75, 1.5))\n",
        "    # ),\n",
        "    # Add gaussian noise.\n",
        "    # For 50% of all images, we sample the noise once per pixel.\n",
        "    # For the other 50% of all images, we sample the noise per pixel AND\n",
        "    # channel. This can change the color (not only brightness) of the\n",
        "    # pixels.\n",
        "    # iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "    # Make some images brighter and some darker.\n",
        "    # In 20% of all cases, we sample the multiplier once per channel,\n",
        "    # which can end up changing the color of the images.\n",
        "    # iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "    # Apply affine transformations to each image.\n",
        "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        # translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        # shear=(-2, 2)\n",
        "    )\n",
        "], random_order=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdelF0KG-4T5"
      },
      "source": [
        "# !cp /content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r2.h5 /content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r3.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bez0c30a66IT"
      },
      "source": [
        "# train_set = NuCLSDataset()\n",
        "# train_set.load_dataset(dataset_dir='/content/drive/MyDrive/QC', fold_num = 2, is_train=True)\n",
        "# train_set.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QjapY3nbrXB"
      },
      "source": [
        "**TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEnKsmSpEJ3"
      },
      "source": [
        "import random\n",
        "\n",
        "for i in range(100):\n",
        "  folds = random.randint(0, 4)\n",
        "  print('i=',i+1,' fold=',folds+1)\n",
        "  # folds = 998\n",
        "  train_set = NuCLSDataset()\n",
        "  train_set.load_dataset(dataset_dir='/content/drive/MyDrive/QC', fold_num = int(folds+1), is_train=True)\n",
        "  train_set.prepare()\n",
        "\n",
        "  valid_dataset = NuCLSDataset()\n",
        "  valid_dataset.load_dataset(dataset_dir='/content/drive/MyDrive/QC', fold_num = int(folds+1), is_train=False)\n",
        "  valid_dataset.prepare()\n",
        "\n",
        "  # if i==0:\n",
        "  model = Mask_RCNN.mrcnn.model.MaskRCNN(mode='training', \n",
        "                            model_dir='/content/drive/MyDrive/maskrcnn/checkpoints/', \n",
        "                            config=Train_config)\n",
        "\n",
        "  model.keras_model.load_weights(filepath='/content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r2.h5', \n",
        "                  by_name=True)\n",
        "\n",
        "  model.train(train_dataset=train_set, \n",
        "        val_dataset=valid_dataset, \n",
        "        learning_rate=Train_config.LEARNING_RATE, \n",
        "        epochs=10,# augmentation = seq,\n",
        "        layers='all')\n",
        "  \n",
        "  model_path = '/content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r2.h5'\n",
        "  model.keras_model.save_weights(model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTeXsAVHJsxH"
      },
      "source": [
        "# model.keras_model.save_weights('/content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhkfc7KXX0Ec"
      },
      "source": [
        "class TestConfig(Mask_RCNN.mrcnn.config.Config):\n",
        "    NAME = \"Test_cfg\"\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    NUM_CLASSES = 7+1\n",
        "\n",
        "\n",
        "Test_config = TestConfig()\n",
        "Test_config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLncHZKFXIPM"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from Mask_RCNN.mrcnn.model import load_image_gt\n",
        "from Mask_RCNN.mrcnn.utils import compute_ap\n",
        "from Mask_RCNN.mrcnn.utils import compute_recall\n",
        "from Mask_RCNN.mrcnn.model import mold_image\n",
        "\n",
        "def evaluate_model(dataset, model, cfg, threshold=0.5):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# print(yhat)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=threshold)\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP\n",
        "\n",
        "def evaluate_model_1(dataset, model, cfg):\n",
        "  APs = list(); ARs = list(); \n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    AR, _ = compute_recall(r[\"rois\"], gt_bbox, iou=0.5) \n",
        "    ARs.append(AR)\n",
        "    APs.append(AP)\n",
        "  # calculate the mean AP across all images\n",
        "  mAP = mean(APs)\n",
        "  mAR = mean(ARs) \n",
        "  return mAP, mAR\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlq1iKoPbwNI"
      },
      "source": [
        "**Testing on Folds 1 to 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4UlKHznFPI"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "import numpy as np\n",
        "import Mask_RCNN.mrcnn.visualize as visualize\n",
        "import Mask_RCNN.mrcnn.utils as utils\n",
        "from Mask_RCNN.mrcnn.model import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PyoNXszXbeE"
      },
      "source": [
        "model = Mask_RCNN.mrcnn.model.MaskRCNN(mode='inference', \n",
        "                          model_dir='/content/', \n",
        "                          config=Test_config)\n",
        "\n",
        "model.keras_model.load_weights(filepath='/content/drive/MyDrive/maskrcnn/NuCLS_mask_rcnn_mclass_r2.h5', \n",
        "                  by_name=True)\n",
        "\n",
        "for folds in range(5):\n",
        "  print(' fold=',folds+1)\n",
        "\n",
        "  valid_dataset = NuCLSDataset()\n",
        "  valid_dataset.load_dataset(dataset_dir='/content/drive/MyDrive/QC', fold_num = int(folds+1), is_train=False)\n",
        "  valid_dataset.prepare()\n",
        "\n",
        "  # test_mAP = evaluate_model(valid_dataset, model, Test_config, threshold=0.5)\n",
        "  # print(\"Test mAP: %.3f\" % test_mAP)\n",
        "\n",
        "  test_mAP, mARs_test = evaluate_model_1(valid_dataset, model, Test_config)\n",
        "\n",
        "  f_score_test = (2 * test_mAP * mARs_test)/(test_mAP + mARs_test)\n",
        "\n",
        "  print(\"Test mAP: %.3f\" % test_mAP)\n",
        "  print('f1-score-test', f_score_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhemS1UfZ8l"
      },
      "source": [
        "pyplot.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "\t# load image and mask\n",
        "\tfor i in range(n_images):\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, _ = dataset.load_mask(i)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Actual')\n",
        "\t\t# plot masks\n",
        "\t\tfor j in range(mask.shape[2]):\n",
        "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.5, interpolation='none')\n",
        "\t\t# get the context for drawing boxes\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Predicted')\n",
        "\t\tax = pyplot.gca()\n",
        "\t\t# plot each box\n",
        "\t\tfor box in yhat['rois']:\n",
        "\t\t\t# get coordinates\n",
        "\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t# calculate width and height of the box\n",
        "\t\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t\t# create the shape\n",
        "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t\t# draw the box\n",
        "\t\t\tax.add_patch(rect)\n",
        "\t# show the figure\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh1I5cLU4A77"
      },
      "source": [
        "pyplot.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "\t# load image and mask\n",
        "\tfor i in range(n_images):\n",
        "\t\tinfo = dataset.image_info[i]\n",
        "\t\timg_path = info['path']\n",
        "\t\tann_path = info['annotation']\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, class_ids = dataset.load_mask(i)\n",
        "\t\t# Compute Bounding box\n",
        "\t\tbbox = utils.extract_bboxes(mask)\n",
        "    # Display image and additional stats\n",
        "\t\t# print(\"image_id \", image_id, valid_dataset.image_reference(image_id))\n",
        "\t\tlog(\"image\", image)\n",
        "\t\tlog(\"mask\", mask)\n",
        "\t\tlog(\"class_ids\", class_ids)\n",
        "\t\tlog(\"bbox\", bbox)\n",
        "\n",
        "    # Run detection\n",
        "\t\tresults = model.detect([image], verbose=1)\n",
        "\n",
        "\t\t# Visualize results\n",
        "\t\tr = results[0]\n",
        "\n",
        "\n",
        "\t\t# # convert pixel values (e.g. center)\n",
        "\t\t# scaled_image = mold_image(image, cfg)\n",
        "\t\t# # convert image into one sample\n",
        "\t\t# sample = expand_dims(scaled_image, 0)\n",
        "\t\t# # make prediction\n",
        "\t\t# # yhat = model.detect(sample, verbose=0)[0]\n",
        "\n",
        "\n",
        "\t\t# Display image and instances\n",
        "\t\tprint(img_path,ann_path)\n",
        "\t\tvisualize.display_instances(image, bbox, mask, class_ids, valid_dataset.class_names, show_mask=False)\n",
        "\t\tvisualize.display_differences(image,\n",
        "                        bbox, class_ids, mask,\n",
        "                        r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
        "                        ['tumor'], title=\"image\" + str(i), ax=None,\n",
        "                        show_mask=False, show_box=True,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tiou_threshold=0.5, score_threshold=0.5)\n",
        "\t\tvisualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], valid_dataset.class_names, show_mask=False)\n",
        "\t\t# print(r['class_ids'])\n",
        "\t\t# print(results)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\t\t# # plot raw pixel data\n",
        "\t\t# pyplot.imshow(image)\n",
        "\t\t# pyplot.title('Predicted')\n",
        "\t\t# ax = pyplot.gca()\n",
        "\t\t# # plot each box\n",
        "\t\t# for box in yhat['rois']:\n",
        "\t\t# \t# get coordinates\n",
        "\t\t# \ty1, x1, y2, x2 = box\n",
        "\t\t# \t# calculate width and height of the box\n",
        "\t\t# \twidth, height = x2 - x1, y2 - y1\n",
        "\t\t# \t# create the shape\n",
        "\t\t# \trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t# \t# draw the box\n",
        "\t\t# \tax.add_patch(rect)\n",
        "\t# show the figure\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw03YYoq2h2J"
      },
      "source": [
        "image_ids = np.random.choice(valid_dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = valid_dataset.load_image(image_id)\n",
        "    mask, class_ids = valid_dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, valid_dataset.class_names)\n",
        "\n",
        "    # Compute Bounding box\n",
        "    bbox = utils.extract_bboxes(mask)\n",
        "\n",
        "    # Display image and additional stats\n",
        "    print(\"image_id \", image_id, valid_dataset.image_reference(image_id))\n",
        "    log(\"image\", image)\n",
        "    log(\"mask\", mask)\n",
        "    log(\"class_ids\", class_ids)\n",
        "    log(\"bbox\", bbox)\n",
        "    # Display image and instances\n",
        "    visualize.display_instances(image, bbox, mask, class_ids, valid_dataset.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9DIK38offLU"
      },
      "source": [
        "folds = 1\n",
        "\n",
        "\n",
        "print(' fold=',folds+1)\n",
        "\n",
        "valid_dataset = NuCLSDataset()\n",
        "valid_dataset.load_dataset(dataset_dir='/content/drive/MyDrive/QC', fold_num = int(folds+1), is_train=False)\n",
        "valid_dataset.prepare()\n",
        "\n",
        "plot_actual_vs_predicted(valid_dataset, model, Test_config, n_images=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfTWG7iSjctq"
      },
      "source": [
        "plot_actual_vs_predicted(valid_dataset, model, Test_config, n_images=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}